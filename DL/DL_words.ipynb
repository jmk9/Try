{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60922baa-7d74-4d13-ad12-49a2fef0ca04",
   "metadata": {},
   "source": [
    "# DL basic words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8d295-642b-4243-a095-63cff1b61b7d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c3b0c-fb41-4921-b735-d66f39abb8dd",
   "metadata": {},
   "source": [
    "### CNN(Convolution layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c5959-9661-44ba-9c64-31f2dd1c05dd",
   "metadata": {},
   "source": [
    "Conv2D(filters=n, kernel_size=(n, n), strides=(n, n), padding='', activation='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368fb0c-3dfb-4fcd-9c92-36ae58f2d719",
   "metadata": {},
   "source": [
    "- filters는 layer에서 나갈 때 몇 개의 filter를 만들 것인지  \n",
    "- kernel_size는 filter(weight)의 size. (n, n)으로 써도 되고 n이라고 써도 됨  \n",
    "- strides는 몇 개의 pixel을 skip하면서 지나갈 것인지  \n",
    "- activation은 어떠한 activation function을 사용할 것인지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0b226-1302-494c-86c6-6be174c28173",
   "metadata": {},
   "source": [
    "### activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4fffc1-69f3-423f-a882-430491acef32",
   "metadata": {},
   "source": [
    "layer = Dense(n, activation='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0034cd-7ec0-4f9c-a86a-2a5a0d765739",
   "metadata": {},
   "source": [
    "- 우리의 neuron(ai에 있어서 neural network)은 여러 경로를 통해 들어온 전기신호의 합이 일정치 이상이 되면 다음 neuron으로 신호를 전달한다. 여기서 일정치를 정하는 기준이 activation function이다. 이전 layer의 output 즉, 다음 layer에 입력되는 input에 가중치(weight)를 곱한 것을 다음 layer로 넘기기 전에 activation function을 거치는 것이다. 굳이 activation function을 거치는 이유는 linear한 weight의 function으로는 non-linear한 model을 표현할 수 없기 때문이다.  \n",
    "- activation function 종류에는 Sigmoid, Tanh, softmax, ReLU, Leaky ReLU, ELU 등이 있다. 이 중 실제로 많이 쓰이는 것은 ReLU, softmax이다.\n",
    "- softmax는 흔히 multi-class classification(다중분류)에서 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d726b48-6fe2-470e-9805-95130cf750ed",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83434b5-4094-4ea1-8593-a9c1ea3c285b",
   "metadata": {},
   "source": [
    "model.compile(loss='', optimizer='', metrics='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a31cf-5da3-44a2-9d8d-49927770d548",
   "metadata": {},
   "source": [
    "- neural network를 거쳐서 나온 결과와 실제의 차이(loss)를 계산하는 함수이다. 즉, 학습이 올바르게 진행되는지 확인하기 위해 사용한다.\n",
    "- loss function의 종류에는 MSE(Mean Squared Error), RMSE(Root Mean Squared Error), Binary Crossentropy, Categorical Crossentropy 등이 있다. label이 2개일 때는 Binary Crossentropy, 2개 이상일 경우에는 Categorical Crossentropy를 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14686e04-e5c5-462e-bf73-838a8f992805",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032c420-0d5e-482c-80a3-bdeba5907215",
   "metadata": {},
   "source": [
    "- 아까 loss function에서 input에 weight를 곱한다고 했는데 여기서 loss를 줄이는 방향으로 weight와 gradient를 계산하여 재설정하는 과정을 거쳐 최적의 weight를 가진 model을 만들어내는 과정을 optimizer(최적화)라고 한다.\n",
    "- optimizer의 종류에는 gradient descent, Momentum, RMSProp, Adam 등이 있다. 실제로 많이 쓰이는 것은 Momentum과 RMSProp의 장점을 합친 Adam이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7c053-6621-42ab-8bd1-5294ab2dd077",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42231c-4ea7-4630-81d9-8336a85279b5",
   "metadata": {},
   "source": [
    "- metrics(척도)는 어떤 model을 평가하기 위해 사용하는 값이다. loss function과 혼동하면 안 된다. 개념은 흡사하다.\n",
    "- metrics의 종류에는 Accuracy(정확도), Precision(정밀도), Recall(재현율), F1 Score 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf813017-4136-474f-b738-c33f22c1e37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
